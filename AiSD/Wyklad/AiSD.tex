\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage[polish]{babel}
\usepackage{amsmath}
\usepackage{tikz}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{hyperref}
\usepackage{float}
\usepackage{graphicx}



\title{Algorytmy i Struktury Danych}
\author{Wojciech Typer}
\date{}

\begin{document}
\maketitle

\begin{algorithm}[H]
\caption{Insertion Sort}\label{alg:insertion_sort}
\begin{algorithmic}[1]
\Procedure{InsertionSort}{A, n}
    \For{$i = 1$ to $n-1$}
        \State $key = A[i]$
        \State $j = i - 1$
        \While{$j \geq 0$ and $A[j] > key$}
            \State $A[j+1] = A[j]$
            \State $j = j - 1$
        \EndWhile
        \State $A[j+1] = key$
    \EndFor
\EndProcedure
\end{algorithmic}
\end{algorithm} 
\vspace{1\baselineskip}
\textbf{Złożoność czasowa:} $O(n^2)$ \par
\textbf{Best case:} w najlepszym przypadku złożoność czasowa będzie wynosić $O(n)$ \par
\textbf{Złożoność pamięciowa:} $O(1)$
\vspace{2\baselineskip}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{/home/wojteq18/Pobrane/zdjecia/insert-sort.png}
    \label{fig:example_image}
\end{figure}
\vspace{3\baselineskip}

\begin{algorithm}[H]
    \caption{Merge Sort}\label{alg:merge_sort}
    \begin{algorithmic}[1]
    \Procedure{MergeSort}{A, 1, n}
        \If{|A[1..n]| == 1} 
            \State \Return{A[1..n]}
        \Else
            \State $B = \text{MergeSort}(A, 1, \lfloor n/2 \rfloor)$
            \State $C = \text{MergeSort}(A, \lfloor n/2 \rfloor, n)$
            \State \Return{Merge(B, C)}
        \EndIf
    \EndProcedure
    \end{algorithmic}    
\end{algorithm}
\begin{algorithm}[H]
    \caption{Merge}\label{alg:merge}
    \begin{algorithmic}[1]
    \Procedure{Merge}{X[1..k], Y[1..n]}
        \If{$X = \emptyset$}
            \State \Return{$Y$}
        \ElsIf{$Y = \emptyset$}
            \State \Return{$X$}
        \ElsIf{$X[1] \leq Y[1]$}
            \State \Return{$[X[1]] \times \text{Merge}(X[2..k], Y[1..n])$}   
        \Else
            \State \Return{$[Y[1]] \times \text{Merge}(X[1..k], Y[2..n])$}
        \EndIf
    \EndProcedure
    \end{algorithmic}       
\end{algorithm}
\vspace{1\baselineskip}
\textbf{Złożoność czesowa Merge Sort:} $O(n \log n)$ \par
\textbf{Złożoność pamięciowa Merge Sort:} $O(n)$
\vspace{2\baselineskip}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{/home/wojteq18/Pobrane/Merge_sort_algorithm_diagram.svg.png}
    \label{fig:example_image}
\end{figure}
\vspace{2\baselineskip} \par
Istnieje również iteracyjna wersja algorytmu Merge, sort, która została \par
przedstawiona poniżej w postaci pseudokodu.
\begin{algorithm}[H]
    \caption{IterativeMergeSort}\label{alg:iterative_merge}
    \begin{algorithmic}[1]
        \Procedure{IterativeMergeSort}{A[1..n]}
            \For{$size = 1$ \textbf{to} $n-1$ \textbf{by} $size \times 2$}
                \For{$left = 0$ \textbf{to} $n-1$ \textbf{by} $2 \times size$}
                    \State $mid \gets \min(left + size - 1, n - 1)$
                    \State $right \gets \min(left + 2 \times size - 1, n - 1)$
                    \State \Call{Merge}{A, left, mid, right}
                \EndFor
            \EndFor
        \EndProcedure
    \end{algorithmic}
\end{algorithm}
\vspace{1\baselineskip}
\textbf{Złożoność czasowa Iterative Merge Sort:} $O(n \log n)$ - dzieje się tak, \par
ponieważ size jest podwajany o 2 w każdej iteracji, więc potrzebujemy \par
około $ \log_2 n$ iteracji, a w każdej z nich wykonujemy $O(n)$ operacji. \par
\vspace{1\baselineskip}
\textbf{Złożoność pamięciowa Iterative Merge Sort:} $O(n)$ \par
\vspace{1\baselineskip}
\textbf{Notacja asymptotyczna}
O:f(n) = O(g(n)) $\rightarrow (\exists c > 0) (\exists n_0 \in N) : \forall n \geq n_0 \rightarrow 0 \leq f(n) \leq c \cdot g(n)$ \par
\vspace{1\baselineskip}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{/home/wojteq18/Pobrane/zdjecia/images.png}
    \label{fig:example_image}
\end{figure}
\vspace{1\baselineskip}
$f(n) = O(g(n)) \rightarrow lim_{n \to \infty} \frac{|f(n)|}{|g(n)|} < \infty$ \par
\vspace{1\baselineskip}
\textbf{Notacja asymptotyczna - własności} \par
\vspace{1\baselineskip}
a) $f(n) = n^3 + O(n^2) \rightarrow (\exists h(n) = O(n^2))(f(n) = n^3 + h(n))$ \par
\vspace{1\baselineskip}
b) $n^2 + O(n) = O(n^2) \rightarrow (\forall f(n) = O(n))(\exists h(n) = O(n^2))(n^2 + f(n)-h(n))$ \par
\vspace{1\baselineskip}
\textbf{Notacja $\Omega$} \par
\vspace{1\baselineskip}
$f(n) = \Omega (g(n)) \rightarrow(\exists c > 0)(\exists n_0 \in N)(\forall n \geq n_0)(c * g(n) \leq |f(n))$ \par
\vspace{1\baselineskip}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{/home/wojteq18/Pobrane/zdjecia/1a7d9c3f882e7a237b30f5eb6defa1aa45c6ab22.png}
    \label{fig:example_image}
\end{figure}
\vspace{7\baselineskip}
\textbf{Notacja $\Omega$ - własności} \par
\vspace{1\baselineskip}
a) $n^3 = \Omega (2n^2)$ \par
\vspace{1\baselineskip}
b) $n = \Omega (log(n))$ \par
\vspace{1\baselineskip}
c) $2n^2 = \Omega (n^2)$ \par
\vspace{1\baselineskip}
\textbf{Notacja $\Theta$} \par
\vspace{1\baselineskip}
$f(n) = \Theta (g(n)) \rightarrow (\exists c_1, c_2 > 0)(\exists n_0 \in N)(\forall n  \geq n_0)(c_1 g(n) \leq $ \par $|f(n) \leq c_2 g(n))$ \par
\vspace{1\baselineskip}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{/home/wojteq18/Pobrane/zdjecia/theeta.png}
    \label{fig:example_image}
\end{figure}
\vspace{1\baselineskip}
$\Theta (f(n)) = O(f(n)) \cap \Omega (f(n))$ \par
\vspace{1\baselineskip}
\textbf{Notacja o- małe} \par
\vspace{1\baselineskip}
$f(n) = o(g(n)) \rightarrow (\forall c > 0)(\exists n_0 \in N)(\forall n \geq n_0)(|f(n)| < c * |g(n)|)$ \par
\vspace{1\baselineskip}
\textbf{Notacja o- małe - przykłady} \par
\vspace{1\baselineskip}
a) $117n log(n) = o(n^2)$ \par
\vspace{1\baselineskip}
b) $ n^2 = o(n^3)$ \par
\vspace{1\baselineskip}
\textbf{Notacja $\omega$} \par
\vspace{1\baselineskip}
$f(n) = \omega (g(n)) \rightarrow (\forall c > 0)(\exists n_0 \in N)(\forall n \geq n_0)(|f(n)| > c * |g(n)|)$ \par
\vspace{1\baselineskip}
$lim_{n \to \infty} \frac{|f(n)|}{|g(n)|} = \infty$ \par
\vspace{1\baselineskip}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{/home/wojteq18/Pobrane/zdjecia/allnotations.png}
    \label{fig:example_image}
\end{figure}
\vspace{1\baselineskip}
\textbf{Rekurencje} \par
\vspace{1\baselineskip}
Metoda podstawiania (metoda dowodzenia indukcyjnego) \par
    \hspace{20pt}1. Zgadnij odpowiedź (bez stałych) \par
    \hspace{20pt}2. Sprawdź przez indukcję, czy dobrze zgadliśmy \par
    \hspace{20pt}3. Znajdź stałe \par
\vspace{1\baselineskip}
Przykład 1: \par
\vspace{1\baselineskip}
$T(n) = 4T(\frac{n}{2}) + n$   \par
Pierwszy strzał: $T(n) = O(n^3)$ \par
Cel: pokazać, że $(\exists c > 0) T(n) \leq c * n^3$ \par
Krok początkowy: $T(1) = \Theta (1) = c * 1^3 = c$ \par
Krok indukcyjny: zał. że, $(\forall_(k < n)) (T(k) \leq c * k^3) = $ \par
Dowód: $T(n) = 4T(\frac{n}{2}) + n \leq 4c * (\frac{n}{2})^3 + n = \frac{1}{2}cn^3 + n =$ \par
$= cn^3 - \frac{1}{2}cn^3 + n = cn^3 - (\frac{1}{2}cn^3 - n) \leq cn^3$ \par
Pokazaliśmy, że $T(n) = O(n^2)$ \par
\vspace{1\baselineskip}
Spróbujmy wzmocnić zał. indukcyjne: $T(n) \leq c_1 n^2 - c_2 n$ \par
$T(n) \leq 4T(\frac{n}{2}) + n \leq 4(c_1 (\frac{n}{2})^2 - c_2 \frac{n}{2}) + n = $ \par
$ = c_1 n^2 - 2c_2 n + n = c_1 n^2 - (2c_2 - 1)n \leq c_1 n^2 - c_2 n$ \par
Musimy dobrać takie $c_1 i c _2$, aby $2c_1 \geq c_2$ \par
Wówczas otrzymamy $T(1) = O(1) \leq c_1 1^2 - c_2 1$ \par
\vspace{9\baselineskip}
Przykład 2: \par
\vspace{1\baselineskip}
$T(n) = 2T(\sqrt{n}) + log(n)$ \par
Załóżmy, że n jest potęgą dwójki $n = 2^m \rightarrow m = log(n)$ \par
$T(2^m) = 2T(2^{m/2}) + m$ \par
oznaczmy $T(2^m) = S(m)$ \par
$T(2^m) = 2T(2^{m/2}) + m \rightarrow 2S(m/2) + m$ \par
$S(m) = O(m log(m))$ \par
$T(n) = O(log(n) log(log(n)))$ (formalnie powinniśmy to udowodnić) \par  
\vspace{1\baselineskip}
\textbf{Drzewo rekursji} \par
\vspace{1\baselineskip}
Przykład : $T(n) = T(\frac{n}{2}) +T (\frac{n}{4}) + n^2$ \par
\vspace{1\baselineskip}
\begin{center}
    \begin{tikzpicture}
        [level distance=1.5cm,
        level 1/.style={sibling distance=4cm},
        level 2/.style={sibling distance=2cm}]
        \node {$n^2$}
            child {node {$\frac{n^2}{4}$}
                child {node {$\frac{n^2}{16}$}}
                child {node {$\frac{n^2}{64}$}}
            }
            child {node {$\frac{n^2}{16}$}
                child {node {$\frac{n^2}{64}$}}
                child {node {$\frac{n^2}{256}$}}
            };
          \node[draw=none] at (-4.5,0) {$n^2$};
          \node[draw=none] at (-4.5,-1.5) {$\frac{5}{16}n^2$};
          \node[draw=none] at (-4.5,-3) {$\frac{25}{256}n^2$};
    \end{tikzpicture}
\end{center}
\vspace{1\baselineskip}
Trzeba pamiętać, że drzewo rekursji samo w sobie nie jest formalnym rozwiązaniem problemu. Nie można go urzywać do dowodzenia złożoności algorytmów.
Jest to jedynie intuicyjne podejście do problemu. Formmalnie T(n) należałoby policzyć jako sumę wszystkich wierzchołków w drzewie rekursji:
\[
    T(n) = \sum^{\infty}_{k=0} \left(\frac{5}{16}\right)^k \cdot n^2 = n^2 \sum^{\infty}_{k=0} \left(\frac{5}{16}\right)^k = n^2 \frac{1}{1-\frac{5}{16}} = n^2 \frac{16}{11} = \frac{16}{11}n^2
\]
Widzimy zatem, że $T(n) = O(n^2)$ \par
\vspace{1\baselineskip}
\textbf{Master Theorem} \par
\vspace{1\baselineskip}
Niech $a \geq 1, b > 1, f(n), d \in N$ oraz $f(n)$ będzie funkcją nieujemną. Rozważmy rekurencję: \par
\[
    T(n) = aT(\frac{a}{b}) + \Theta(n^d)
\] 
Wówczas: \par
\begin{itemize}
    \item $\Theta(n^d)$, jeśli $d > log_b a$
    \item $\Theta (n^d log(n))$, jeśli $d = log_b a$
    \item $\Theta(n^{log_b a})$, jeśli $d < log_b a$
\end{itemize}
Do przedstawienia problemu użyjemy drzewa rekursji. Rozważmy rekurencję:
\[
    T(n) = aT(\frac{n}{b}) + \Theta(n^d)
\]
\begin{center}
\begin{tikzpicture}
    [level distance=1.5cm,
    level 1/.style={sibling distance=4cm},
    level 2/.style={sibling distance=2cm}]
    \node {$c \cdot n^d$}
        child {node {$c \cdot \left(\frac{n}{b}\right)^d$}
            child {node {$c \cdot \left(\frac{n}{b^2}\right)^d$}}
            child {node {$c \cdot \left(\frac{n}{b^2}\right)^d$}}
        }
        child {node {$c \cdot \left(\frac{n}{b}\right)^d$}
            child {node {$c \cdot \left(\frac{n}{b^2}\right)^d$}}
            child {node {$c \cdot \left(\frac{n}{b^2}\right)^d$}}
        };
      \node[draw=none] at (-4.5,0) {$n^d$};
      \node[draw=none] at (-4.5,-1.5) {$\frac{n^d}{b^d}$};
      \node[draw=none] at (-4.5,-3) {$\frac{n^d}{b^{2d}}$};
  \end{tikzpicture} 
\end{center}
\begin{enumerate}
    \item suma kosztoów w $k$--tym kroku
        \[
            a^k c (\frac{n}{b^k})^d = c (\frac{a}{b^d})^k n^d
        \]
        gdzie $c(\frac{n}{b^k})^d$ to koszt jednego podproblemu w $k$--tym kroku
    \item obliczenie wysokości drzewa:
        \[
            \frac{n}{b^h} = 1 \rightarrow h = \log_b n
        \]
    \item Obliczenie $T(n)$
    \begin{align*}
        T(n) &= \Theta\left(\sum^{\log_b n}_{k=0} c\frac{a}{b^k}n^d\right) \\
             &= \Theta\left(c \cdot n^d \sum^{\log_b n}_{k=0} \left(\frac{a}{b^d}\right)^k\right) \\
             &= \Theta\left(c \cdot n^d \frac{1-\left(\frac{a}{b^d}\right)^{\log_b n + 1}}{1-\frac{a}{b^d}}\right) \\
             &\implies T(n) = \Theta(n^d)
    \end{align*}
    
    \item rozważmy 3 przypadki:
        \begin{enumerate}
            \item $d > \log_b a$ 
                \[
                    T(n) = \Theta(n^d)
                \]
            \item $d = \log_b a$ 
                \[
                    T(n) = \Theta(n^d \log n)
                \]
            \item $d < \log_b a$
                \[
                    T(n) = \Theta(n^{\log_b a})
                \]
        \end{enumerate}
\end{enumerate}

\subsubsection*{Przykłady}
\begin{itemize}
    \item $T(n) = 4T(\frac{n}{2}) + 11n$ \newline
        Wtedy kożystając z \textbf{Master Theorem} mamy:
        \[
            a = 4, b = 2, d = 1
        \]
        Jak i również
        \[
            \log_b a = \log_2 4 = 2 > 1 = d \implies T(n) = \Theta(n^2)
        \]
    \item $T(n) = 4T(\frac{n}{3}) + 3n^2$ \newline
        Wtedy
        \[
            a = 4, b = 3, d = 2
        \]
        Jak i również
        \[
            \log_b a = \log_3 4 < 2 = d \implies T(n) = \Theta(n^2)
        \]
    \item $T(n) = 27T(\frac{n}{3}) + \frac{n^2}{3}$ \newline
        Wtedy
        \[
            a = 27, b = 3, d = 2
        \]
        Jak i również
        \[
            \log_b a = \log_3 27 = 3 > 2 = d \implies T(n) = \Theta(n^3\log n)
        \]
\end{itemize}

\subsection*{Metoda dziel i zwyciężaj (D\&C)}
Na czym ona polega?
\begin{enumerate}
    \item Podział problemu na mniejsze podproblemy 
    \item Rozwiazanie rekurencyjnie mniejsze podpoblemy
    \item połącz rozwiązania podproblemów w celu rozwiązania problemu wejściowego
\end{enumerate}
\subsubsection*{Algorytm -- Binary Search}
\begin{itemize}
    \item \textbf{Input}: posortowania tablica \texttt{A[1..n]} oraz element \texttt{x}
    \item \textbf{Output}: indeks \texttt{i} taki, że \texttt{A[i] = x} lub \texttt{0} jeśli \texttt{x} nie występuje w \texttt{A}
        \item przebieg algorytmu: 
            \begin{algorithm}[H]
                \caption{Binary Search}
                \begin{algorithmic}[1]
                    \Procedure{BinarySearch}{A, x}
                        \State $l = 1$
                        \State $r = |A|$
                        \While{$l \leq r$}
                            \State $m = \lfloor \frac{l+r}{2} \rfloor$
                            \If{$A[m] = x$}
                                \State \Return{$m$}
                            \ElsIf{$A[m] < x$}
                                \State $l = m + 1$
                            \Else
                                \State $r = m - 1$
                            \EndIf
                        \EndWhile
                        \State \Return{0}
                    \EndProcedure
                \end{algorithmic}
            \end{algorithm}
        \item \textbf{Asypmtotyka}
            Algorytm spełnia następująca rekurencje:
            \[
                T(n) = T(\frac{n}{2}) + \Theta(1)
            \]
            Rozwiązując za pomocą \textbf{Master Theorem} otrzymujemy:
            \[
                T(n) = \Theta(\log n)
            \]
\end{itemize}

\end{document}